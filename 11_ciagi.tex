\documentclass{mp}
\graphicspath{{11_ciagi}}
\subtitle{Ciągi zmiennych losowych}
\begin{document}
\frame{\titlepage}
\begin{frame}{Zbieżność ciągów}
\only<+>
{
\begin{block}{Zbieżność z prawdopodobieństwem 1 (prawie na pewno)}
\begin{gather*}
P(\{\omega\colon \lim_{n\to\infty}X_n(\omega)=X(\omega)\})=1 \\
P(\lim_{n\to\infty} X_n=X)=1
\end{gather*}
\end{block}
}
\only<+>
{
\begin{block}{Zbieżność wg prawdopodobieństwa (stochastycznie)}
\[\forall\varepsilon>0\colon \lim_{n\to\infty}P(\left|X_n-X\right|\geq\varepsilon)=0\]
\end{block}
}
\only<+>
{
\begin{block}{Zbieżność wg dystrybuanty}
\[\forall x\in A\colon \lim_{n\to\infty} F_n(x) =F(x) \]
\end{block}
\note{$A$ jest zbiorem, gdzie $F$ jest ciągła}
}
\only<+>
{
	\begin{block}{Twierdzenie}
	\begin{enumerate}
	\item Zbieżność prawie na pewno pociąga za sobą zbieżność wg prawdopodobieństwa.
	\item Zbieżność wg prawdopodobieństwa pociąga za sobą zbieżność wg dystrybuanty.
	\end{enumerate}
	\end{block}
}
%nie bardzo wiem po co mi to
%\only<+>
%{
%	\begin{block}{Zbieżność średno z kwadratem}
%		\[ \lim_{n\to\infty} E(X_n-X)^2=0 \]
%		\note{Przy zbieżności średio z kwadratem drugi moment zwykły $X_i$ oraz $X$ musi być skończony}
%	\end{block}
%}
\end{frame}
\begin{frame}{Prawa wielkich liczb}
$(X_1,X_2,\ldots)$ niezależne zmienne losowe

\begin{gather*}
EX_i=\mu_i<\infty \qquad D^2X_i=\sigma_i^2<\infty \\
\uncover<2->{Y_n=\frac{X_1+X_2+\ldots+X_n}{n} \\}
\uncover<3-4>{EY_n=\alt<-3>{\alert{?}}{\frac{\mu_1+\mu_2+\ldots+\mu_n}{n}} \qquad D^2Y_n=\alt<-3>{\alert{?}}{\frac{\sigma_1^2+\sigma_2^2+\ldots+\sigma_n^2}{n^2}}}
\end{gather*}
\end{frame}
\begin{frame}{Słabe prawa wielkich liczb}
\begin{columns}[T]
\begin{column}{.30\textwidth}
\uncover<2->
{
\begin{block}{Markowa}
\[\lim_{n\to\infty} D^2Y_n=0 \]
\end{block}
}
\end{column}
\begin{column}{.30\textwidth}
\uncover<3->
{
\begin{block}{Czebyszewa}
\begin{gather*}
\exists \sigma\in\R_{+}\forall k\in\N \\
\sigma_k^2<\sigma^2
\end{gather*}
\end{block}
}
\end{column}
\begin{column}{.30\textwidth}
\uncover<4->
{
\begin{block}{Chinczyna}
Zmienne $(X_1, X_2, \ldots)$ mają identyczny rozkład prawdopodobieństwa
($EY_n=\mu$)
\end{block}
}
\end{column}
\end{columns}
\begin{block}{}
\[ \forall \varepsilon>0\colon \lim_{n\to\infty} P(\left|Y_n-EY_n\right|<\varepsilon)=1 \]
\end{block}
\end{frame}
\begin{frame}{Mocne prawo wielkich liczb Kołmogorowa}
\[ \sum_{n=1}^\infty \frac{\sigma_n^2}{n^2}<\infty \to P(\lim_{n\to\infty} \left|Y_n-EY_n\right|=0)=1 \]
\end{frame}
\begin{frame}{Centralne twierdzenia graniczne}
\begin{block}{Twierdzenie Lindenberga-Levy'ego}
\[ Z_n=\frac{Y_n-EY_n}{DY_n} \]
Ciąg $(Z_1,Z_2,\ldots)$ jest zbieżny wg dystrybuanty do $Z\sim N(0,1)$.
\end{block}
\end{frame}

\end{document}
