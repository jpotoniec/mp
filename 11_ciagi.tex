\documentclass{mp}
\graphicspath{{11_ciagi}}
\subtitle{Ciągi zmiennych losowych}
\begin{document}
\frame{\titlepage}
\begin{frame}{Zbieżność ciągów}
\only<+>
{
\begin{block}{Zbieżność z prawdopodobieństwem 1 (prawie na pewno)}
\begin{gather*}
P(\{\omega\colon \lim_{n\to\infty}X_n(\omega)=X(\omega)\})=1 \\
P(\lim_{n\to\infty} X_n=X)=1
\end{gather*}
\end{block}
}
\only<+>
{
\begin{block}{Zbieżność wg prawdopodobieństwa (stochastycznie)}
\[\forall\varepsilon>0\colon \lim_{n\to\infty}P(\left|X_n-X\right|\geq\varepsilon)=0\]
\end{block}
}
\only<+>
{
\begin{block}{Zbieżność wg dystrybuanty}
\[\forall x\in A\colon \lim_{n\to\infty} F_n(x) =F(x) \]
\end{block}
\note{$A$ jest zbiorem, gdzie $F$ jest ciągła}
}
\only<+>
{
	\begin{block}{Twierdzenie}
	\begin{enumerate}
	\item Zbieżność prawie na pewno pociąga za sobą zbieżność wg prawdopodobieństwa.
	\item Zbieżność wg prawdopodobieństwa pociąga za sobą zbieżność wg dystrybuanty.
	\end{enumerate}
	\end{block}
}
%nie bardzo wiem po co mi to
%\only<+>
%{
%	\begin{block}{Zbieżność średno z kwadratem}
%		\[ \lim_{n\to\infty} E(X_n-X)^2=0 \]
%		\note{Przy zbieżności średio z kwadratem drugi moment zwykły $X_i$ oraz $X$ musi być skończony}
%	\end{block}
%}
\end{frame}
\begin{frame}{Prawa wielkich liczb}
%TODO: jednak niech założenia będą wspólne dla wszystkich, a te zmieniające się fragmenty będą już elementami poszczególnych twierdzeń
\begin{block}{Założenia}
$(X_1,X_2,\ldots)$ ciąg \alert<1>{niezależnych} zmiennych losowych \only<3->{\alert{o tym samym rozkładzie}}\\
\begin{gather*}
EX_i=\mu_i\only<3->{\alert{=\mu}} \qquad D^2X_i=\sigma_i^2 \\
M_n=\frac{1}{n}\sum_{i=1}^n X_i \qquad EM_n=\alert<1>{?} \qquad D^2(M_n)=\alert<1>{?}
\end{gather*}
\note{\[EM_n=\frac{1}{n}\sum_{i=1}^n \mu_i \qquad D^2(M_n)=\frac{1}{n^2}\sum_{i=1}^n\sigma_i^2\]}
\end{block}
\only<2>
{
\begin{block}{Słabe prawo wielkich liczb Markowa}
%TODO: dziwne, nie mogę się doszukać tego w anglojęzycznym internecie
\[ \forall \varepsilon>0\colon \lim_{n\to\infty} P(\left|M_n-EM_n\right|\geq\varepsilon)=0 \]
\note
{
	Z nierówności Czebyszewa:
	\[P(\left|M_n-EM_n\right|\geq\varepsilon)\leq \frac{D^2(M_n)}{\varepsilon}\]
	Przechodząc obustronnie do granicy otrzymujemy, że prawa strona dąży do 0, a ponieważ lewa strona jest nieujemna, więc również musi dążyć do zera.
}
\end{block}
}
\only<3>
{
\begin{block}{Słabo prawo wielkich liczb Chinczyna}
\[ \forall \varepsilon>0\colon \lim_{n\to\infty} P(\left|M_n-\mu\right|\geq\varepsilon)=0 \]
\note
{
	Ponieważ zmienne są niezależne i mają identycznye rozkłady, niech $D^2X_i=\sigma^2$, wtedy $D^2M_n=\frac{\sigma^2}{n}$. Z nierówności Czebyszewa
	\[P(\left|M_n-\mu\right|\geq\varepsilon)\leq \frac{\sigma^2}{n\varepsilon} \]
	Przechodząc obustronnie do granicy otrzymujemy, że prawa strona dąży do 0, a ponieważ lewa strona jest nieujemna, więc również musi dążyć do zera.
}
\end{block}
}
\only<4>
{
	%TODO: na oko to tu brakuje jakiegoś ważnego założenia, bo wychodzi, że to dominuje słabe prawo wielkich liczb Chinczyna
\begin{block}{Mocne prawo wielkich liczb}
\[P(\lim_{n\to\infty} M_n=\mu)=1\]
\note{Nie dowodzimy, dowód jest dość złożony}
\end{block}
}
\end{frame}
\begin{frame}{Centralne twierdzenia graniczne}
\begin{block}{Założenia}
$(X_1,X_2,\ldots)$ ciąg niezależnych zmiennych losowych o tym samym rozkładzie
\begin{gather*}
EX_i=\mu \qquad D^2X_i=\sigma^2\neq0 \\
\only<2->{Y_n=\sum_{i=1}^n X_i \qquad EY_n=\alert<2>{?} \qquad DY_n=\alert<2>{?}}\\
\only<3->{Z_n=\frac{Y_n-EY_n}{DY_n} \qquad EZ_n=\alert<3>{?} \qquad DZ_n=\alert<3>{?}}
\end{gather*}
\end{block}
\only<4->
{
\begin{block}{Twierdzenie Lindenberga-Levy'ego}
Ciąg $(Z_1,Z_2,\ldots)$ jest zbieżny wg dystrybuanty do $Z\sim N(0,1)$.
\end{block}
}
\end{frame}
\end{document}
