\documentclass{mp}
\graphicspath{{11_ciagi}}
\subtitle{Ciągi zmiennych losowych}
\begin{document}
\frame{\titlepage}
\begin{frame}{Zbieżność ciągów}
\only<1>
{
\begin{block}{Zbieżność z prawdopodobieństwem 1 (prawie na pewno)}
\begin{gather*}
P(\{\omega\colon \lim_{n\to\infty}X_n(\omega)=X(\omega)\})=1 \\
P(\lim_{n\to\infty} X_n=X)=1
\end{gather*}
\end{block}
}
\only<2>
{
\begin{block}{Zbieżność wg prawdopodobieństwa (stochastycznie)}
\[\forall\varepsilon>0\colon \lim_{n\to\infty}P(\left|X_n-X\right|<\varepsilon)=1\]
\end{block}
}
\only<3>
{
\begin{block}{Zbieżność wg dystrybuanty}
\[\forall x\in A\colon \lim_{n\to\infty} F_n(x) =F(x) \]
\end{block}
\note{$A$ jest zbiorem, gdzie $F$ jest ciągła}
}
\only<1-3>
{
\begin{block}{Przykład}
\begin{gather*}
\Omega=\left<0;1\right> \\
X_n(\omega)=\begin{cases} 1 & \omega\in\left<0,\frac{1}{n}\right)\\0 & \omega\in\left<\frac{1}{n},1\right> \end{cases} \qquad P(X_n=1)=\frac{1}{n}\\
P(X=0)=1
\end{gather*}
\note<1>
{
	Szukamy zbioru $A=\{\omega\colon \lim_{n\to\infty} X_n(\omega)=0\}$.
	Rozpatrzmy ciąg $(X_n(\omega))$ dla dowolnego ustalonego $\omega$.
	Z definicji granicy ciągu $\lim_{n\to\infty} X_n(\omega)=0$ wtedy i tylko wtedy gdy \[\forall \varepsilon>0\exists N\in\N \forall n>N\colon \left|a_n-0\right|<\varepsilon\]
	Musimy ustalić od którego momentu $X_n(\omega)<\varepsilon$, to znaczy $X_n(\omega)=0$:
	\[ X_n(\omega)=0 \iff \omega\geq\frac{1}{n} \iff n\geq\frac{1}{\omega} \iff N=\lceil\frac{1}{\omega}\rceil \]
	pod warunkiem, że $\omega\neq 0$.
	Dla $\omega=0$ nie jesteśmy w stanie znaleźć odpowiedniego $N$, a zatem $A=\left(0,1\right>=\Omega\backslash\{0\}$.
}
\note<2>
{
	\[ \forall \varepsilon>0\colon \lim_{n\to\infty} P\left(\{\omega\colon \left|X_n(\omega)-X(\omega)\right|\right<\varepsilon)=1 \]
	Ponieważ zmienne $X_n$ są binarne, a $X=0$, to jest to równoważne poniższemu stwierdzeniu
	\begin{gather*}
	 \lim_{n\to\infty} P\left(\{\omega\colon X_n(\omega)=0\}\right)=1 \\
	\end{gather*}
	Z definicji $P(X_n=0)=1-\frac{1}{n}$, a ponieważ $\lim_{n\to\infty} \left(1-\frac{1}{n}\right)=1$, to $(X_n)$ jest zbieżny jak powinien.
}
\note<3>
{
	\[ F_n(x)=\begin{cases} 0 & x\leq 0 \\ 1-\frac{1}{n} & 0<x\leq 1 \\ 1 & x>1 \end{cases} \qquad F(x)=\begin{cases} 0 & x\leq 0 \\ 1 & x>0 \end{cases} \]
	Rozpatrujemy $\lim_{n\to\infty} F_n(x)=F(x)$ dla dowolnego $x\in\R\backslash\{0\}$ (w zerze $F(x)$ jest nieciągła).
	\begin{enumerate}
	\item Dla $x<0$: $\lim_{n\to\infty} 0=0$, a więc zachodzi.
	\item Dla $x>1$: $\lim_{n\to\infty} 1=1$, a więc zachodzi.
	\item Dla $0<x\leq 1$: $\lim_{n\to\infty} 1-\frac{1}{n}=1$, a więc również zachodzi.
	\end{enumerate}
}
\end{block}
}
\only<4>
{
	\begin{block}{Twierdzenie}
	\begin{enumerate}
	\item Zbieżność prawie na pewno pociąga za sobą zbieżność wg prawdopodobieństwa.
	\item Zbieżność wg prawdopodobieństwa pociąga za sobą zbieżność wg dystrybuanty.
	\end{enumerate}
	\end{block}
}
%nie bardzo wiem po co mi to
%\only<+>
%{
%	\begin{block}{Zbieżność średno z kwadratem}
%		\[ \lim_{n\to\infty} E(X_n-X)^2=0 \]
%		\note{Przy zbieżności średio z kwadratem drugi moment zwykły $X_i$ oraz $X$ musi być skończony}
%	\end{block}
%}
\end{frame}
\begin{frame}{Prawa wielkich liczb}
$(X_1,X_2,\ldots)$ niezależne zmienne losowe

\begin{gather*}
EX_i=\mu_i<\infty \qquad D^2X_i=\sigma_i^2<\infty \\
\uncover<2->{Y_n=\frac{(X_1-\mu_1)+(X_2-\mu_2)+\ldots+(X_n-\mu_n)}{n} \\}
\uncover<3-4>{EY_n=\alt<-3>{\alert{?}}{0} \qquad D^2Y_n=\alt<-3>{\alert{?}}{\frac{\sigma_1^2+\sigma_2^2+\ldots+\sigma_n^2}{n^2}}}
\end{gather*}
\end{frame}
\begin{frame}{Słabe prawa wielkich liczb}
\begin{columns}[T]
\begin{column}{.30\textwidth}
\uncover<2->
{
\begin{block}{Markowa}
\[\lim_{n\to\infty} D^2Y_n=0 \]
\end{block}
}
\end{column}
\begin{column}{.30\textwidth}
\uncover<3->
{
\begin{block}{Czebyszewa}
\begin{gather*}
\exists \sigma\in\R_{+}\forall k\in\N \\
\sigma_k^2<\sigma^2
\end{gather*}
\end{block}
}
\end{column}
\begin{column}{.30\textwidth}
\uncover<4->
{
\begin{block}{Chinczyna}
Zmienne $(X_1, X_2, \ldots)$ mają identyczny rozkład prawdopodobieństwa
($EY_n=\mu$)
\end{block}
}
\end{column}
\end{columns}
\begin{block}{}
\[ \forall \varepsilon>0\colon \lim_{n\to\infty} P(\left|Y_n-0\right|<\varepsilon)=1 \]
\end{block}
\end{frame}
\begin{frame}{Mocne prawo wielkich liczb Kołmogorowa}
\[ \sum_{n=1}^\infty \frac{\sigma_n^2}{n^2}<\infty \to P(\lim_{n\to\infty} Y_n=0)=1 \]
\end{frame}
\begin{frame}{Centralne twierdzenia graniczne}
\begin{block}{Twierdzenie Lindenberga-Levy'ego}
\[ Z_n=\frac{Y_n-0}{DY_n} \]
Ciąg $(Z_1,Z_2,\ldots)$ jest zbieżny wg dystrybuanty do $Z\sim N(0,1)$.
\end{block}
\end{frame}

\end{document}
